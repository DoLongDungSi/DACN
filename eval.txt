Báo cáo Đánh giá và Khắc phục Lỗi Hệ thống Chấm điểmVới vai trò là một kiến trúc sư phần mềm cấp cao chuyên về đánh giá và kiểm thử các hệ thống phức tạp, bản phân tích này sẽ đi sâu vào việc kiểm tra toàn diện quy trình chấm điểm của dự án "ML Judge" của bạn. Theo yêu cầu, báo cáo sẽ tập trung hoàn toàn vào việc xác định các lỗi chức năng, lỗ hổng logic và các điểm yếu trong kiến trúc có thể ảnh hưởng trực tiếp đến trải nghiệm của người dùng (thí sinh) và quản trị viên (người tạo đề bài). Các yếu tố về hiệu suất, bảo mật và tối ưu hóa ở cấp độ doanh nghiệp sẽ được bỏ qua để phù hợp với bối cảnh của một dự án học đường.Mục tiêu của báo cáo này là cung cấp một cái nhìn sâu sắc, chi tiết về các vấn đề hiện tại và đưa ra các giải pháp khắc phục cụ thể, kèm theo mã nguồn đã được chỉnh sửa. Phân tích sẽ bao quát toàn bộ vòng đời của một lượt nộp bài, từ khi người dùng tải file lên, qua quá trình giao tiếp giữa các dịch vụ, đến việc thực thi script chấm điểm và cuối cùng là lưu kết quả vào cơ sở dữ liệu.Tổng quan Kiến trúc Quy trình Chấm điểmĐể hiểu rõ các lỗi tiềm ẩn, trước tiên cần phải phân tích luồng xử lý dữ liệu và logic từ đầu đến cuối của hệ thống. Quy trình này bao gồm sự tương tác phức tạp giữa nhiều thành phần, và sự ổn định của nó phụ thuộc vào một "hợp đồng" ngầm giữa các thành phần này.Hành trình của một Lượt nộp bài: Phân tích Từng bướcQuá trình chấm điểm, mặc dù có vẻ đơn giản từ góc độ người dùng, thực chất là một chuỗi các bước phối hợp giữa frontend, backend và một microservice chuyên dụng.Hành động của Người dùng: Người dùng, thông qua giao diện web, chọn một bài toán và tải lên một file submission.csv.Điểm tiếp nhận tại Backend (backend/routes/submissions.js): Yêu cầu được gửi đến máy chủ backend Node.js. Endpoint này nhận diện problemId và file do người dùng tải lên. Nhiệm vụ đầu tiên của nó là truy vấn cơ sở dữ liệu để thu thập tất cả các thành phần cần thiết cho việc chấm điểm: nội dung file submission của người dùng, script đánh giá (evaluation_script) và dữ liệu đáp án (ground_truth_content) do quản trị viên cung cấp khi tạo bài toán.Giao tiếp Liên dịch vụ: Backend sau đó đóng gói tất cả các nội dung này (submission, ground truth, script) vào một đối tượng JSON. Đối tượng này được gửi thông qua một yêu cầu POST đến microservice chấm điểm bằng Python. Địa chỉ của microservice này được định nghĩa trong file docker-compose.yml thông qua biến môi trường EVALUATION_SERVICE_URL.Thực thi tại Microservice (microservice/app.py): Ứng dụng Flask của microservice nhận payload JSON. Nó tiến hành tạo ra một môi trường thực thi tạm thời bằng cách ghi nội dung của submission, ground truth, dữ liệu test công khai, và script đánh giá vào các file riêng biệt trong một thư mục tạm. Sau đó, nó gọi trình thông dịch Python như một tiến trình con (subprocess), truyền đường dẫn đến các file tạm này làm đối số dòng lệnh.Logic của Script Đánh giá (db/init.sql): Script Python do quản trị viên cung cấp bắt đầu thực thi trong môi trường biệt lập này. Script này được kỳ vọng sẽ đọc file submission, so sánh nó với file ground truth, và cuối cùng ghi một con số duy nhất (điểm số) vào một file output được chỉ định. Các script mẫu trong file db/init.sql cho thấy chúng chứa logic nội bộ để xử lý các loại lỗi khác nhau, chẳng hạn như lỗi định dạng và lỗi tính toán.Truyền tải Kết quả: Sau khi script con kết thúc, microservice đọc điểm số từ file output, đo lường thời gian thực thi, và đóng gói kết quả cuối cùng (bao gồm trạng thái, điểm số, thời gian chạy, và thông báo lỗi nếu có) vào một phản hồi JSON. Phản hồi này được gửi trở lại cho backend Node.js.Lưu trữ Dữ liệu: Backend nhận phản hồi từ microservice, diễn giải trạng thái và điểm số, sau đó chèn một bản ghi mới vào bảng submissions trong cơ sở dữ liệu PostgreSQL, hoàn tất quy trình.Phân tích Cốt lõi: "Hợp đồng Mong manh"Toàn bộ sự ổn định của hệ thống chấm điểm phụ thuộc vào một "hợp đồng" ngầm, không được ghi lại thành văn bản và không được kiểm soát giữa ba thành phần độc lập: backend điều phối, microservice thực thi, và script đánh giá do quản trị viên cung cấp. Bất kỳ sự sai lệch nào trong việc tuân thủ hợp đồng này từ một trong ba bên đều dẫn đến sự sụp đổ của toàn bộ quy trình.Chuỗi giả định này tạo nên một "Hợp đồng Mong manh":Backend (submissions.js) giả định rằng microservice sẽ luôn trả về một đối tượng JSON chứa các trường status, score, runtime_ms, và error.Microservice (app.py) giả định rằng script đánh giá sẽ chấp nhận chính xác bốn đối số dòng lệnh là đường dẫn file theo một thứ tự cụ thể.Microservice tiếp tục giả định rằng nếu script gặp lỗi, nó sẽ kết thúc một cách "lịch sự" bằng cách ghi một "con số ma thuật" (ví dụ: -1.0 hoặc 0.0) vào file output và thoát với mã trạng thái khác không.Script đánh giá (ví dụ trong db/init.sql) giả định rằng môi trường thực thi của nó đã được cài đặt sẵn các thư viện cần thiết như pandas hay sklearn.Chuỗi giả định này là một điểm yếu nghiêm trọng trong kiến trúc. Không có schema, phiên bản, hay cơ chế kiểm tra tự động nào để đảm bảo các giả định này luôn đúng. Một thay đổi nhỏ, chẳng hạn như một quản trị viên viết script yêu cầu năm đối số, hoặc một thư viện bị gỡ bỏ khỏi môi trường của microservice, sẽ gây ra một lỗi khó hiểu và khó gỡ rối.Phân tích các Lỗi Nghiêm trọng trong Microservice Đánh giáMicroservice Python (microservice/app.py) là trái tim của bộ máy chấm điểm. Trách nhiệm chính của nó là thực thi một đoạn mã không đáng tin cậy (script của admin) một cách an toàn và diễn giải kết quả của nó một cách chính xác. Quá trình phân tích đã phát hiện ra nhiều sai sót nghiêm trọng trong việc triển khai logic này.Lỗi: Xung đột trong Cơ chế Xử lý Lỗi (check=True và Báo cáo Lỗi từ Script)Một trong những lỗi logic nghiêm trọng nhất nằm ở cách microservice gọi và xử lý kết quả từ script đánh giá.Bằng chứng: Microservice thực thi script đánh giá bằng cách sử dụng subprocess.run(..., check=True,...). Đồng thời, các script đánh giá mẫu trong db/init.sql được thiết kế để chủ động gọi sys.exit(1) sau khi phát hiện lỗi và ghi mã lỗi (-1.0 hoặc 0.0) vào file output.Phân tích: Tham số check=True khiến cho hàm subprocess.run ngay lập tức ném ra một ngoại lệ CalledProcessError nếu script con trả về một mã thoát khác không (điều mà sys.exit(1) thực hiện). Điều này làm gián đoạn khối try chính trong app.py trước khi nó có cơ hội đọc file output mà script vừa ghi. Mặc dù khối except có cố gắng đọc lại file này, luồng điều khiển trở nên phức tạp và không đáng tin cậy. Cơ chế dự kiến—script thông báo loại lỗi của nó thông qua file output—bị phá vỡ bởi cờ check=True quá "hung hăng".Hệ quả: Sự xung đột này cho thấy một sự hiểu lầm cơ bản về quản lý tiến trình con. Hệ thống hiện có hai "nguồn chân lý" cạnh tranh nhau về việc một lần chấm có thất bại hay không: mã thoát của script và nội dung của file output. Việc triển khai hiện tại ưu tiên mã thoát, thực tế đã bỏ qua thông tin chi tiết hơn mà chính script cung cấp (ví dụ, sự khác biệt giữa lỗi định dạng -1.0 và lỗi tính toán 0.0). Người dùng cuối cùng chỉ nhận được một thông báo lỗi chung chung như "Script exited with error code 1", và thông tin cụ thể về lý do thất bại bị mất đi.Lỗi: Logic Xác thực Điểm số Mơ hồ và Sai lầmNgay cả khi script thực thi thành công (trả về mã thoát 0), logic xác thực điểm số trong microservice vẫn có vấn đề.Bằng chứng: Bên trong khối try của app.py, sau khi thực thi thành công script, có một đoạn kiểm tra: if score < 0:... score = 0.0.Phân tích: Logic này có hai vấn đề. Thứ nhất, nó giả định một kịch bản phi lý rằng một script có thể thoát thành công với mã 0 nhưng lại ghi ra một điểm số âm, điều này vi phạm hợp đồng đã thiết lập. Thứ hai, nếu sự kiện không mong muốn này xảy ra, nó âm thầm chuyển đổi điểm số âm không hợp lệ thành 0.0. Điều này hợp nhất hai trạng thái lỗi hoàn toàn khác nhau: "script trả về điểm không hợp lệ" và "script gặp lỗi trong quá trình tính toán", cả hai bây giờ đều dẫn đến điểm số là 0. Điều này phá hủy thông tin gỡ rối có giá trị.Hệ quả: Đây là một ví dụ về việc thiếu "lập trình phòng thủ". Hệ thống không nên âm thầm "sửa chữa" dữ liệu không hợp lệ. Nó nên coi một điểm số âm bất ngờ từ một script đã thoát thành công là một trạng thái lỗi riêng biệt, và truyền một thông báo lỗi rõ ràng trở lại backend (ví dụ: "Script đánh giá thành công nhưng trả về điểm số âm không hợp lệ").Lỗi: Mất mát Chi tiết và Thiếu nhất quán trong Truyền tải LỗiCách microservice đóng gói và trả về thông tin lỗi cũng làm giảm khả năng gỡ rối của hệ thống.Bằng chứng: Các khối except trong app.py đã nắm bắt chính xác đầu ra lỗi tiêu chuẩn (stderr) từ script thất bại. Tuy nhiên, backend trong submissions.js chỉ đơn giản là chuyển đổi toàn bộ thông báo lỗi thành một chuỗi duy nhất và lưu vào cột JSONB evaluation_details.Phân tích: Mặc dù lỗi được lưu trữ, cấu trúc của nó đã bị mất. Một traceback Python, một câu lệnh print tùy chỉnh ra stderr, và một thông báo hết thời gian chờ đều bị làm phẳng thành một chuỗi văn bản duy nhất. Điều này gây khó khăn cho frontend trong việc phân tích và hiển thị thông báo lỗi thân thiện với người dùng. Đối với một quản trị viên đang gỡ rối script của họ, việc xem một traceback thô là hữu ích, nhưng đối với một người dùng, một thông báo như "File nộp của bạn sai số dòng" sẽ tốt hơn nhiều. Việc triển khai hiện tại không thể phân biệt giữa các trường hợp này.Hệ quả: Hệ thống thiếu một định dạng lỗi có cấu trúc cho việc giao tiếp giữa các dịch vụ. Một cách tiếp cận tốt hơn là microservice trả về một đối tượng JSON như {"error_type": "FORMAT_ERROR", "details": "Thiếu cột: 'prediction'"} hoặc {"error_type": "RUNTIME_ERROR", "details": "Traceback:..."}. Điều này sẽ cho phép backend và frontend xử lý lỗi một cách thông minh hơn.Các Lỗ hổng trong Trình xử lý Submission phía BackendPhần này kiểm tra mã nguồn Node.js trong backend/routes/submissions.js, đóng vai trò là người điều phối. Nhiệm vụ chính của nó là thu thập dữ liệu và quản lý giao tiếp với microservice. Tại đây, chúng ta tìm thấy lỗi nghiêm trọng nhất, làm tê liệt toàn bộ hệ thống.Lỗi Nghiêm trọng: Không cung cấp public_test_contentĐây là lỗi nghiêm trọng nhất trong toàn bộ dự án, khiến chức năng cốt lõi không thể hoạt động.Bằng chứng: Lệnh gọi axios.post trong submissions.js bao gồm public_test_content: publicTestContent trong payload của nó. Tuy nhiên, biến publicTestContent được khai báo nhưng không bao giờ được gán giá trị. Truy vấn cơ sở dữ liệu trước đó chỉ lấy evaluation_script và ground_truth_content từ bảng problems.Phân tích: Đây là một điểm chặn hoàn toàn đối với hệ thống chấm điểm. Microservice (app.py) có một bước kiểm tra đầu vào if not all([submission_content, ground_truth_content, public_test_content, script_content]) sẽ luôn thất bại vì public_test_content bị thiếu trong yêu cầu. Do đó, mọi nỗ lực nộp bài cho bất kỳ bài toán nào cũng sẽ thất bại ngay lập tức trước cả khi script đánh giá được thực thi.Hệ quả: Lỗi này là kết quả của việc triển khai luồng dữ liệu không đầy đủ. Nguyên nhân sâu xa nằm ở bước tạo bài toán (sẽ được phân tích trong Mục 4), nhưng biểu hiện của nó ở đây đã phá vỡ hoàn toàn tính năng nộp bài đối với người dùng. Điều này cho thấy sự thiếu sót trong việc kiểm thử end-to-end, vì lỗi này sẽ được phát hiện ngay lập tức nếu có một quy trình kiểm thử hoàn chỉnh. Toàn bộ quy trình chấm điểm sụp đổ theo kịch bản sau:Người dùng nộp một file.submissions.js được kích hoạt và truy vấn cơ sở dữ liệu để lấy thông tin bài toán.Bản ghi trong cơ sở dữ liệu không chứa nội dung của file test công khai.Biến publicTestContent vẫn là undefined.axios.post gửi một payload JSON đến microservice thiếu khóa public_test_content.app.py nhận yêu cầu, data.get('public_test_content') trả về None.Kiểm tra if not all([...]) thất bại.Microservice ngay lập tức trả về lỗi 400 Bad Request với thông báo "Missing... public_test... content".Khối catch trong submissions.js được kích hoạt, và người dùng nhận được một thông báo lỗi chung chung "Evaluation service error". Hệ thống thất bại.Lỗi: Mất tính Đặc thù trong Xử lý LỗiLogic phía backend đã chủ động loại bỏ thông tin lỗi có giá trị mà microservice cung cấp, dẫn đến trải nghiệm người dùng kém.Bằng chứng: Logic backend kiểm tra một cách rõ ràng if (evaluationResult.score === -1) và, khi tìm thấy, nó đặt evaluationResult.score = null trước khi lưu vào cơ sở dữ liệu. Trạng thái cuối cùng được xác định bởi một biểu thức điều kiện đơn giản: finalStatus =...? 'succeeded' : 'failed'.Phân tích: Logic này đã loại bỏ thông tin lỗi cụ thể do microservice cung cấp. "Con số ma thuật" -1, có ý nghĩa là "Lỗi Định dạng", bị chuyển đổi thành một giá trị null chung chung. Điều này có nghĩa là tất cả các loại lỗi—lỗi định dạng, lỗi tính toán, hết thời gian chờ, hoặc script bị sập—đều được lưu trữ giống hệt nhau trong cơ sở dữ liệu với status: 'failed' và public_score: null.Hệ quả: Đây chính là hành vi "đần" mà bạn đã mô tả. Hệ thống đã nhận được các tín hiệu lỗi riêng biệt nhưng sau đó lại cố tình hợp nhất chúng thành một trạng thái mơ hồ duy nhất. Điều này ngăn cản giao diện người dùng có thể thông báo cho người dùng tại sao bài nộp của họ thất bại. Đây không chỉ là một cơ hội bị bỏ lỡ để cải thiện trải nghiệm người dùng; nó là một sự thụt lùi chức năng một cách chủ động. Thông tin đã có sẵn trong một khoảnh khắc và sau đó bị phá hủy.Sai sót trong Quy trình Tạo Đề bài và Hợp đồng ScriptPhần này chuyển trọng tâm sang góc nhìn của quản trị viên, phân tích các file backend/routes/problems.js và db/init.sql. Các sai sót trong cách tạo ra các bài toán và cách dữ liệu liên quan được lưu trữ chính là nguyên nhân gốc rễ của các lỗi nghiêm trọng được thấy trong quá trình nộp bài.Lỗi Gốc rễ: Loại bỏ Nội dung testCsv khi Tải lênĐây là nguồn gốc của lỗi nghiêm trọng đã làm tê liệt toàn bộ hệ thống.Bằng chứng: Trong backend/routes/problems.js, hàm handleProblemSave xử lý file testCsv được tải lên. Nó chỉ trích xuất tên file gốc để lưu dưới dạng siêu dữ liệu (datasets.push({ split: 'public_test', filename: file.originalname })) nhưng không bao giờ sử dụng hoặc lưu trữ nội dung của file, vốn có sẵn trong file.buffer. Ngược lại, nội dung của groundTruthCsv lại được lưu trữ một cách chính xác thông qua groundTruthContent = file.buffer.toString('utf-8').Phân tích: Đây là nguồn gốc của lỗi nghiêm trọng được xác định trong Mục 3.1. Dữ liệu cho tập test công khai được nhận từ quản trị viên nhưng ngay lập tức bị loại bỏ. Lược đồ cơ sở dữ liệu trong init.sql cũng thiếu một cột chuyên dụng để lưu trữ nội dung này, chỉ có các cột datasets JSONB, evaluation_script TEXT, và ground_truth_content TEXT. Thiết kế này về cơ bản là không hoàn chỉnh.Hệ quả: Điều này cho thấy một lỗ hổng thiết kế bắt nguồn từ việc xử lý dữ liệu file không nhất quán. Nhà phát triển đã xác định đúng rằng ground_truth_content và evaluation_script cần được lưu trữ trực tiếp trong cơ sở dữ liệu dưới dạng văn bản. Tuy nhiên, họ đã không áp dụng logic tương tự cho public_test.csv, coi nó như siêu dữ liệu đơn giản. Sự không nhất quán này phá vỡ toàn bộ chuỗi logic phụ thuộc vào nội dung của file này để xác thực bài nộp.Lỗ hổng Thiết kế: Hợp đồng Script Mong manh và Không được Kiểm soátHệ thống đặt một gánh nặng quá lớn lên vai quản trị viên, yêu cầu họ phải tuân thủ một hợp đồng phức tạp và không được ghi lại rõ ràng.Bằng chứng: Định nghĩa duy nhất về cách một script đánh giá nên hoạt động được tìm thấy trong các script mẫu bên trong db/init.sql và script mặc định trong frontend/src/components/Problem/ProblemEditorForm.tsx. Không có bất kỳ cơ chế xác thực phía máy chủ, tài liệu hóa, hay cơ chế thực thi nào.Phân tích: Thiết kế này đặt một gánh nặng to lớn lên quản trị viên, yêu cầu họ phải là một lập trình viên hoàn hảo. Họ phải nhớ:Chấp nhận chính xác bốn đối số dòng lệnh.Triển khai hai khối try...except riêng biệt cho ValueError và Exception.Ghi đúng "con số ma thuật" (-1.0 hoặc 0.0) vào file output trong mỗi trường hợp lỗi.Gọi sys.exit(1) trong cả hai trường hợp thất bại.Đảm bảo tất cả các thư viện cần thiết đều có trong môi trường của microservice.Hệ quả: Đây là một thiết kế mong manh và dễ gây lỗi. Một hệ thống mạnh mẽ hơn sẽ trừu tượng hóa sự phức tạp này khỏi quản trị viên. Ví dụ, microservice có thể cung cấp một thư viện chuẩn hoặc một trình bao bọc (wrapper) mà script của quản trị viên có thể nhập vào. Quản trị viên sau đó chỉ cần gọi các hàm như evaluator.record_format_error("Thiếu cột") hoặc evaluator.record_score(0.95), và thư viện sẽ xử lý việc ghi file và các mã thoát. Với tình hình hiện tại, một sai lầm nhỏ của quản trị viên trong logic script của họ có thể dẫn đến các lỗi khó hiểu cho tất cả người dùng nộp bài cho bài toán đó.Tổng hợp Khuyến nghị và Hành động Khắc phụcPhần cuối cùng này cung cấp một kế hoạch hành động toàn diện và cụ thể để khắc phục tất cả các vấn đề đã được xác định. Các bản sửa lỗi được trình bày theo một thứ tự logic, bắt đầu từ các vấn đề lưu trữ dữ liệu nền tảng và tiến dần lên các lớp dịch vụ cao hơn.Bảng: Tóm tắt các Vấn đề được Xác định và Kế hoạch Khắc phụcBảng dưới đây cung cấp một cái nhìn tổng quan về các lỗi, mức độ ảnh hưởng và tóm tắt giải pháp, giúp bạn ưu tiên các hành động cần thực hiện.ID LỗiFile bị ảnh hưởngTác động đến Người dùngMức độTóm tắt Giải phápCR-01problems.js, submissions.js, init.sqlTất cả các lượt nộp bài đều thất bại ngay lập tức.Nghiêm trọngThêm cột public_test_content vào DB, lưu nội dung khi tạo bài toán, và tải nó khi chấm bài.HI-01microservice/app.py, db/init.sqlLỗi script (ví dụ: sai định dạng) bị báo cáo sai thành lỗi sập hệ thống chung chung.CaoGỡ bỏ check=True khỏi subprocess.run và kiểm tra mã thoát thủ công để cho phép báo cáo lỗi một cách tường minh.HI-02backend/routes/submissions.jsCác loại lỗi cụ thể (định dạng vs. tính toán) bị mất, dẫn đến phản hồi kém cho người dùng.CaoSửa đổi backend để bảo toàn tín hiệu lỗi từ microservice và lưu trữ chi tiết lỗi có cấu trúc vào cơ sở dữ liệu.ME-01microservice/app.pyĐiểm không hợp lệ từ một script "thành công" bị chuyển đổi âm thầm, che giấu các lỗi tiềm ẩn.Trung bìnhCoi các điểm số không mong muốn từ các script thoát thành công là một trạng thái lỗi riêng biệt.ME-02ProblemEditorForm.tsx, db/init.sqlQuản trị viên có thể dễ dàng viết các script không tuân thủ, gây ra các lỗi không thể đoán trước.Trung bìnhCải thiện tài liệu trong script đánh giá mặc định để làm cho "hợp đồng" trở nên rõ ràng và minh bạch.Bước 1 (Sửa lỗi Nghiêm trọng): Chỉnh sửa Mô hình và Luồng Dữ liệuMục tiêu của bước này là khắc phục lỗi nghiêm trọng (CR-01) bằng cách đảm bảo public_test_content được lưu trữ và truy xuất một cách chính xác.Hành động 1.1: Cập nhật Lược đồ Cơ sở dữ liệuTrong file db/init.sql, hãy thêm một cột mới vào bảng problems để lưu trữ nội dung của file test công khai.File: db/init.sqlSQL-- Sửa đổi trong phần CREATE TABLE problems
CREATE TABLE problems (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    difficulty VARCHAR(20) NOT NULL,
    content TEXT NOT NULL,
    problem_type VARCHAR(50) NOT NULL,
    author_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    datasets JSONB,
    evaluation_script TEXT,
    ground_truth_content TEXT,
    public_test_content TEXT -- DÒNG MỚI: Thêm cột này
);
Hành động 1.2: Lưu Nội dung testCsv khi Tạo/Cập nhật Bài toánTrong backend/routes/problems.js, hãy sửa đổi hàm handleProblemSave để đọc và lưu nội dung của file testCsv vào cột mới.File: backend/routes/problems.jsJavaScript//... bên trong hàm handleProblemSave...

let datasets = (isUpdate && Array.isArray(existingDatasets))?
    existingDatasets.filter(d => d && typeof d === 'object' && d.split && d.filename)
    :;
let groundTruthContent = null;
let publicTestContent = null; // BIẾN MỚI: Để lưu nội dung test public

const files = req.files;

//... xử lý trainCsv không đổi...

// Sửa đổi xử lý Test Public CSV
if (files && files.testCsv && files.testCsv) {
    const file = files.testCsv;
    datasets = datasets.filter(d => d.split!== 'public_test');
    datasets.push({ split: 'public_test', filename: file.originalname });
    publicTestContent = file.buffer.toString('utf-8'); // LƯU NỘI DUNG
    console.log(`Processed public test file: ${file.originalname}`);
}

//... xử lý groundTruthCsv không đổi...

// --- Database Transaction ---
let client;
let savedProblemId = problemId;
try {
    client = await pool.connect();

    // Xác định nội dung groundTruthContent và publicTestContent để lưu
    if (!groundTruthContent && isUpdate && problemId) {
        const existingContentRes = await client.query('SELECT ground_truth_content FROM problems WHERE id = $1', [problemId]);
        if (existingContentRes.rows.length > 0) groundTruthContent = existingContentRes.rows.ground_truth_content;
    }
    if (!publicTestContent && isUpdate && problemId) { // LÀM TƯƠNG TỰ CHO PUBLIC TEST
        const existingContentRes = await client.query('SELECT public_test_content FROM problems WHERE id = $1', [problemId]);
        if (existingContentRes.rows.length > 0) publicTestContent = existingContentRes.rows.public_test_content;
    }

    //...
    // Sửa đổi câu lệnh INSERT và UPDATE
    if (isUpdate) {
        //...
        const updateQuery = `
            UPDATE problems
            SET name = $1, difficulty = $2, content = $3, problem_type = $4, datasets = $5,
                evaluation_script = $6, ground_truth_content = $7, public_test_content = $8
            WHERE id = $9 RETURNING id`;
        const result = await client.query(updateQuery,);
        //...
    } else {
        const insertQuery = `
            INSERT INTO problems (name, difficulty, content, problem_type, author_id, datasets, evaluation_script, ground_truth_content, public_test_content)
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9) RETURNING id`;
        const result = await client.query(insertQuery,);
        //...
    }
    //...
} //...
Hành động 1.3: Tải và Gửi public_test_content khi Chấm bàiCuối cùng, trong backend/routes/submissions.js, hãy cập nhật truy vấn để lấy public_test_content và gửi nó đến microservice.File: backend/routes/submissions.jsJavaScript//... bên trong router.post('/')...
try {
    //...
    // --- Lấy Dữ liệu Bài toán từ DB ---
    const problemRes = await client.query(
        'SELECT evaluation_script, ground_truth_content, public_test_content FROM problems WHERE id = $1', // THÊM public_test_content
        [problemId]
    );

    if (problemRes.rows.length === 0) {
        return res.status(404).json({ message: 'Problem not found.' });
    }

    const evaluationScript = problemRes.rows.evaluation_script;
    const groundTruthContent = problemRes.rows.ground_truth_content;
    const publicTestContent = problemRes.rows.public_test_content; // LẤY DỮ LIỆU

    if (!evaluationScript ||!groundTruthContent ||!publicTestContent) { // KIỂM TRA CẢ 3
        return res.status(500).json({ message: 'Problem is missing critical evaluation data (script, ground truth, or public test).' });
    }

    // --- Gọi Microservice Đánh giá ---
    const microserviceUrl = process.env.EVALUATION_SERVICE_URL |

| 'http://microservice:5002/evaluate';
    console.log(`Calling evaluation microservice at ${microserviceUrl}`);
    let evaluationResult;
    try {
        const response = await axios.post(microserviceUrl, {
            submission_file_content: submissionFile.buffer.toString('utf-8'),
            ground_truth_content: groundTruthContent,
            public_test_content: publicTestContent, // ĐÃ CÓ DỮ LIỆU
            evaluation_script_content: evaluationScript,
        }, {
            headers: { 'Content-Type': 'application/json' },
            timeout: 60000
        });
        //...
Bước 2: Tăng cường sự Mạnh mẽ cho MicroserviceMục tiêu của bước này là khắc phục xung đột xử lý lỗi (HI-01) và logic xác thực điểm số mơ hồ (ME-01) trong microservice/app.py.Hành động 2.1: Sửa đổi Logic Thực thi SubprocessHãy gỡ bỏ check=True và xử lý mã thoát một cách thủ công để cho phép script báo cáo lỗi một cách tường minh.File: microservice/app.pyPython#...
try:
    #...
    command = ['python', script_path, submission_path, ground_truth_path, public_test_path, output_path]
    score = None
    process_error = None

    try:
        process = subprocess.run(
            command,
            capture_output=True,
            text=True,
            # check=True, # GỠ BỎ DÒNG NÀY
            timeout=45,
            encoding='utf-8',
            errors='replace'
        )

        end_time = time.perf_counter()
        runtime_ms = (end_time - start_time) * 1000
        
        stdout = process.stdout
        stderr = process.stderr

        print(f"Script STDOUT:\n{stdout}")
        if stderr:
            print(f"Script STDERR:\n{stderr}")

        # Đọc điểm số từ file output BẤT KỂ mã thoát
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                score_str = f.read().strip()
                score = float(score_str)
        except (IOError, ValueError) as e:
            # Nếu không đọc được file điểm, đây là một lỗi nghiêm trọng
            process_error = f"Không thể đọc hoặc phân tích điểm từ file output: {e}. Nội dung stderr: {stderr}"
            print(process_error)
            # Trả về lỗi hệ thống, vì hợp đồng cơ bản (ghi file) đã bị vi phạm
            return jsonify({"status": "failed", "error": process_error, "score": None, "runtime_ms": runtime_ms}), 200

        # Bây giờ kiểm tra mã thoát
        if process.returncode!= 0:
            # Script đã thất bại, nhưng chúng ta đã có điểm số (có thể là -1 hoặc 0)
            process_error = f"Script thoát với mã lỗi {process.returncode}. Stderr: {stderr}"
            print(process_error)
            # Trả về trạng thái thất bại, nhưng giữ lại điểm số mà script đã báo cáo
            return jsonify({"status": "failed", "error": process_error, "score": score, "runtime_ms": runtime_ms}), 200

        # Nếu mã thoát là 0 (thành công), điểm số phải >= 0
        if score < 0:
            process_error = f"Script thực thi thành công nhưng trả về điểm số âm không hợp lệ: {score}."
            print(process_error)
            # Đây là một lỗi logic, trả về thất bại và không có điểm
            return jsonify({"status": "failed", "error": process_error, "score": None, "runtime_ms": runtime_ms}), 200
        
        # Tất cả đều ổn
        return jsonify({"status": "succeeded", "score": score, "runtime_ms": runtime_ms, "error": None})

    except subprocess.TimeoutExpired as e:
        # Xử lý timeout không thay đổi
        end_time = time.perf_counter()
        runtime_ms = (end_time - start_time) * 1000
        process_error = f"Script chấm điểm đã hết thời gian chờ sau {e.timeout} giây."
        print(process_error)
        return jsonify({"status": "failed", "error": process_error, "score": None, "runtime_ms": runtime_ms}), 200
    
    except Exception as e:
        # Các lỗi không mong muốn khác
        end_time = time.perf_counter()
        runtime_ms = (end_time - start_time) * 1000
        process_error = f"Lỗi không mong muốn trong quá trình thực thi: {str(e)}"
        print(f"Lỗi không mong muốn: {traceback.format_exc()}")
        return jsonify({"status": "failed", "error": process_error, "score": None, "runtime_ms": runtime_ms}), 500

#...
Bước 3: Cải thiện Logic Backend và Phản hồi cho Người dùngMục tiêu là khắc phục việc mất thông tin lỗi cụ thể (HI-02) trong submissions.js.Hành động 3.1: Diễn giải Phản hồi có Cấu trúc từ MicroserviceSửa đổi logic trong submissions.js để diễn giải phản hồi mới từ microservice và lưu trữ thông tin lỗi một cách chính xác.File: backend/routes/submissions.jsJavaScript//... bên trong router.post('/')...
//... sau khi nhận được `evaluationResult` từ axios...

// --- Xử lý Kết quả và Lưu vào Cơ sở dữ liệu ---
let finalStatus = 'failed';
let finalScore = null;
let finalDetails = evaluationResult.error? { error: evaluationResult.error } : null;

if (evaluationResult.status === 'succeeded' && typeof evaluationResult.score === 'number' && evaluationResult.score >= 0) {
    finalStatus = 'succeeded';
    finalScore = evaluationResult.score;
} else {
    // Nếu thất bại, hãy kiểm tra điểm số được báo cáo để xác định loại lỗi
    if (typeof evaluationResult.score === 'number') {
        if (evaluationResult.score === -1.0) {
            finalStatus = 'format_error'; // TRẠNG THÁI MỚI
            if (finalDetails) finalDetails.type = 'FORMAT_ERROR';
        } else if (evaluationResult.score === 0.0) {
            finalStatus = 'runtime_error'; // TRẠNG THÁI MỚI
            if (finalDetails) finalDetails.type = 'RUNTIME_ERROR';
        }
    }
    // Nếu không có điểm số, nó vẫn là 'failed' chung chung (ví dụ: timeout)
}

console.log(`Final Status: ${finalStatus}, Final Score for DB: ${finalScore}`);

const insertQuery = `
    INSERT INTO submissions (problem_id, user_id, status, public_score, runtime_ms, evaluation_details)
    VALUES ($1, $2, $3, $4, $5, $6) RETURNING *`;

const result = await client.query(insertQuery,);

//... phần còn lại của hàm không đổi...
Để hỗ trợ các trạng thái mới này, bạn cũng có thể cân nhắc cập nhật status trong db/init.sql để phản ánh các giá trị mới này, ví dụ: status VARCHAR(50) NOT NULL, -- 'pending', 'succeeded', 'format_error', 'runtime_error', 'failed'.Bước 4: Củng cố Hợp đồng Script cho Quản trị viênMục tiêu là giảm thiểu sự mong manh của thiết kế bằng cách cung cấp hướng dẫn tốt hơn cho quản trị viên (ME-02).Hành động 4.1: Cải thiện Script Mặc định với Tài liệu Chi tiếtTrong frontend/src/components/Problem/ProblemEditorForm.tsx, hãy cập nhật script mặc định với các bình luận chi tiết để hướng dẫn quản trị viên.File: frontend/src/components/Problem/ProblemEditorForm.tsxJavaScriptconst defaultFormatCheckScript = `# Script chấm điểm mẫu - Hướng dẫn chi tiết
# Vui lòng đọc kỹ các bình luận để đảm bảo script của bạn hoạt động chính xác.

import sys
import pandas as pd
import traceback
# Thêm các thư viện cần thiết cho việc tính điểm của bạn, ví dụ:
from sklearn.metrics import accuracy_score

# HỢP ĐỒNG QUAN TRỌNG:
# Script này phải nhận chính xác 4 đối số dòng lệnh theo thứ tự:
# 1. submission_path: Đường dẫn đến file.csv do người dùng nộp.
# 2. ground_truth_path: Đường dẫn đến file.csv chứa đáp án.
# 3. public_test_path: Đường dẫn đến file.csv test công khai (dùng để kiểm tra định dạng).
# 4. output_path: Đường dẫn đến file.txt nơi script phải ghi điểm số cuối cùng.

# QUY TẮC GHI ĐIỂM VÀO FILE OUTPUT:
# - Ghi "-1.0": Nếu file submission của người dùng sai định dạng (sai cột, sai số dòng, v.v.).
# - Ghi "0.0": Nếu định dạng đúng nhưng có lỗi xảy ra trong quá trình TÍNH ĐIỂM (ví dụ: lỗi chia cho 0).
# - Ghi điểm số >= 0: Nếu mọi thứ thành công.

def evaluate(submission_path, ground_truth_path, public_test_path, output_path):
    """
    Quy trình khuyến nghị:
    1. Bọc toàn bộ logic kiểm tra định dạng trong một khối try...except ValueError.
       - Nếu có lỗi định dạng, bắt ValueError, ghi -1.0 vào output_path và thoát với sys.exit(1).
    2. Nếu định dạng đúng, thực hiện tính điểm.
       - Bọc logic tính điểm trong một khối try...except chung.
       - Nếu có lỗi trong quá trình này, bắt Exception, ghi 0.0 vào output_path và thoát với sys.exit(1).
    3. Nếu tính điểm thành công, ghi điểm số (>= 0) vào output_path.
    """
    required_columns = ['id', 'prediction']
    final_score = -1.0 # Mặc định là lỗi định dạng

    try:
        # === PHẦN 1: KIỂM TRA ĐỊNH DẠNG ===
        print("Bắt đầu kiểm tra định dạng...")
        try:
            sub_df = pd.read_csv(submission_path)
            test_df = pd.read_csv(public_test_path)
        except Exception as e:
            raise ValueError(f"Không thể đọc file submission hoặc public test: {e}")

        # Kiểm tra các cột bắt buộc
        missing_cols = [col for col in required_columns if col not in sub_df.columns]
        if missing_cols:
            raise ValueError(f"File submission thiếu các cột bắt buộc: {missing_cols}")
        
        # Kiểm tra số dòng
        if len(sub_df)!= len(test_df):
            raise ValueError(f"File submission có {len(sub_df)} dòng, nhưng file test yêu cầu {len(test_df)} dòng.")

        # Kiểm tra cột 'id'
        if 'id' in test_df.columns:
            if not sub_df['id'].sort_values().reset_index(drop=True).equals(test_df['id'].sort_values().reset_index(drop=True)):
                raise ValueError("Cột 'id' trong file submission không khớp với file test.")

        # Kiểm tra giá trị null/NaN
        if sub_df.isnull().values.any():
            raise ValueError("File submission chứa giá trị thiếu (NaN/Null).")
        
        # Kiểm tra kiểu dữ liệu cột 'prediction'
        if not pd.api.types.is_numeric_dtype(sub_df['prediction']):
            raise ValueError("Cột 'prediction' phải chứa dữ liệu dạng số.")
        
        print("--- Định dạng OK ---")

        # === PHẦN 2: TÍNH ĐIỂM ===
        print("Bắt đầu tính điểm...")
        final_score = 0.0 # Đặt mặc định là 0 nếu có lỗi xảy ra trong phần này
        
        try:
            gt_df = pd.read_csv(ground_truth_path)
        except Exception as e:
            # Lỗi này nghiêm trọng, không thể chấm điểm
            raise RuntimeError(f"Không thể đọc file ground truth: {e}")

        #!!! THAY THẾ LOGIC TÍNH ĐIỂM CỦA BẠN VÀO ĐÂY!!!
        # Ví dụ: Giả sử cột target trong ground truth là 'label'
        if 'id' not in gt_df.columns or 'label' not in gt_df.columns:
            raise ValueError("File ground truth thiếu cột 'id' hoặc 'label'.")

        merged_df = pd.merge(sub_df[['id', 'prediction']], gt_df[['id', 'label']], on='id', how='inner')
        
        if len(merged_df)!= len(sub_df):
            raise RuntimeError(f"Lỗi khi kết hợp submission và ground truth. Kiểm tra lại cột 'id'.")

        # Ví dụ tính accuracy cho bài toán classification
        calculated_score = accuracy_score(merged_df['label'], merged_df['prediction'].round().astype(int))
        
        final_score = calculated_score # Gán điểm số cuối cùng nếu tính toán thành công
        print(f"Điểm tính được: {final_score}")
        print("--- Tính điểm OK ---")

    except ValueError as format_error:
        # Bắt lỗi định dạng từ PHẦN 1
        print(f"LỖI ĐỊNH DẠNG: {format_error}", file=sys.stderr)
        final_score = -1.0
        try:
            with open(output_path, 'w') as f:
                f.write(str(final_score))
        except Exception as write_e:
            print(f"Lỗi khi ghi điểm lỗi định dạng (-1): {write_e}", file=sys.stderr)
        sys.exit(1) # Quan trọng: Thoát với mã lỗi

    except Exception as calc_error:
        # Bắt lỗi tính toán hoặc các lỗi khác từ PHẦN 2
        print(f"LỖI TÍNH TOÁN/KHÁC: {traceback.format_exc()}", file=sys.stderr)
        final_score = 0.0
        try:
            with open(output_path, 'w') as f:
                f.write(str(final_score))
        except Exception as write_e:
            print(f"Lỗi khi ghi điểm lỗi tính toán (0): {write_e}", file=sys.stderr)
        sys.exit(1) # Quan trọng: Thoát với mã lỗi

    # === PHẦN 3: GHI ĐIỂM THÀNH CÔNG ===
    try:
        with open(output_path, 'w') as f:
            f.write(str(final_score))
        print(f"Ghi điểm cuối cùng thành công: {final_score}")
    except Exception as e:
        print(f"Lỗi nghiêm trọng khi ghi điểm cuối cùng ({final_score}): {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv)!= 5:
        print("Usage: python <script> <submission.csv> <ground_truth.csv> <public_test.csv> <output.txt>", file=sys.stderr)
        sys.exit(1)
    evaluate(sys.argv, sys.argv, sys.argv, sys.argv)
    print("Chấm điểm hoàn tất.")
`;
Kết luận và Các bước Tiếp theoBáo cáo này đã xác định một loạt các lỗi chức năng và lỗ hổng thiết kế trong hệ thống chấm điểm của dự án, từ các vấn đề nghiêm trọng làm tê liệt hệ thống đến các sai sót logic làm giảm chất lượng phản hồi cho người dùng. Lỗi nghiêm trọng nhất, CR-01, bắt nguồn từ việc không lưu và truyền tải nội dung của file test công khai, khiến mọi nỗ lực nộp bài đều thất bại. Các lỗi quan trọng khác bao gồm sự xung đột trong cơ chế xử lý lỗi giữa microservice và script đánh giá, cũng như việc backend chủ động loại bỏ thông tin lỗi chi tiết.Bằng cách thực hiện các hành động khắc phục được nêu trong Mục 5 theo thứ tự—bắt đầu bằng việc sửa đổi cơ sở dữ liệu và luồng dữ liệu, sau đó củng cố logic của microservice và backend—hệ thống chấm điểm sẽ không chỉ hoạt động trở lại mà còn trở nên mạnh mẽ và cung cấp phản hồi có ý nghĩa hơn nhiều cho cả người dùng và quản trị viên.Sau khi áp dụng các bản sửa lỗi này, hệ thống sẽ có khả năng:Chấm điểm thành công: Luồng dữ liệu hoàn chỉnh sẽ cho phép các bài nộp được xử lý từ đầu đến cuối.Phân biệt các loại lỗi: Hệ thống sẽ có thể phân biệt giữa lỗi định dạng của người dùng và lỗi thực thi trong script của quản trị viên, cho phép hiển thị các thông báo phù hợp.Cung cấp thông tin gỡ rối tốt hơn: Chi tiết lỗi sẽ được lưu trữ một cách có cấu trúc, tạo nền tảng cho việc xây dựng một giao diện người dùng thông minh hơn trong tương lai.Việc tuân thủ các khuyến nghị này sẽ đảm bảo dự án của bạn đáp ứng được các yêu cầu chức năng cốt lõi một cách đáng tin cậy.